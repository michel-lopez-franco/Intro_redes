{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 14:44:38.035488: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1730925878.064231  418715 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1730925878.070168  418715 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suprime mensajes de advertencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Configuración de memoria GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU(s) encontrada(s): 2\n",
      "\n",
      "Información del dispositivo:\n",
      "Dispositivos disponibles: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "Dispositivo por defecto: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# Configuración de entorno\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # Usa solo la GPU 0\n",
    "\n",
    "# Configuración de TensorFlow\n",
    "try:\n",
    "    # Configuración de memoria GPU\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"GPU(s) encontrada(s): {len(gpus)}\")\n",
    "    else:\n",
    "        print(\"No se encontraron GPUs, usando CPU\")\n",
    "\n",
    "    # Configuración de optimizaciones CPU\n",
    "    tf.config.threading.set_inter_op_parallelism_threads(4)\n",
    "    tf.config.threading.set_intra_op_parallelism_threads(4)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error en configuración: {e}\")\n",
    "\n",
    "# Verificar configuración\n",
    "print(\"\\nInformación del dispositivo:\")\n",
    "print(\"Dispositivos disponibles:\", tf.config.list_physical_devices())\n",
    "print(\"Dispositivo por defecto:\", tf.config.get_visible_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Información del entorno TensorFlow:\n",
      "Versión de TensorFlow: 2.18.0\n",
      "GPU disponible: True\n",
      "\n",
      "Dispositivos físicos:\n",
      "  CPU: /physical_device:CPU:0\n",
      "  GPU: /physical_device:GPU:0\n",
      "  GPU: /physical_device:GPU:1\n",
      "\n",
      "Prueba de operación básica:\n",
      "Operación en CPU exitosa: /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Operación en GPU exitosa: /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Operación en GPU exitosa: /job:localhost/replica:0/task:0/device:GPU:1\n"
     ]
    }
   ],
   "source": [
    "def verificar_configuracion():\n",
    "    \"\"\"\n",
    "    Verifica la configuración de TensorFlow y muestra información relevante\n",
    "    \"\"\"\n",
    "    print(\"\\nInformación del entorno TensorFlow:\")\n",
    "    print(f\"Versión de TensorFlow: {tf.__version__}\")\n",
    "    print(f\"GPU disponible: {len(tf.config.list_physical_devices('GPU')) > 0}\")\n",
    "    \n",
    "    # Información de dispositivos\n",
    "    print(\"\\nDispositivos físicos:\")\n",
    "    for device in tf.config.list_physical_devices():\n",
    "        print(f\"  {device.device_type}: {device.name}\")\n",
    "    \n",
    "    # Prueba de operaciones básicas\n",
    "    print(\"\\nPrueba de operación básica:\")\n",
    "    with tf.device('/CPU:0'):\n",
    "        a = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "        b = tf.constant([[5.0, 6.0], [7.0, 8.0]])\n",
    "        c = tf.matmul(a, b)\n",
    "        print(f\"Operación en CPU exitosa: {c.device}\")\n",
    "    \n",
    "    if len(tf.config.list_physical_devices('GPU')) > 0:\n",
    "        for gpu in tf.config.list_physical_devices('GPU'):\n",
    "            with tf.device(f'/GPU:{gpu.name.split(\":\")[-1]}'):\n",
    "                a = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "                b = tf.constant([[5.0, 6.0], [7.0, 8.0]])\n",
    "                c = tf.matmul(a, b)\n",
    "                print(f\"Operación en {gpu.device_type} exitosa: {c.device}\")\n",
    "\n",
    "verificar_configuracion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración para mejor rendimiento\n",
    "tf.config.optimizer.set_jit(True)  # Habilita XLA JIT\n",
    "tf.config.optimizer.set_experimental_options({\n",
    "    'layout_optimizer': True,\n",
    "    'constant_folding': True,\n",
    "    'shape_optimization': True,\n",
    "    'remapping': True,\n",
    "    'arithmetic_optimization': True,\n",
    "    'dependency_optimization': True,\n",
    "    'loop_optimization': True,\n",
    "    'function_optimization': True,\n",
    "    'debug_stripper': True,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 15:03:06.607532: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1730926986.634927  443332 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1730926986.641069  443332 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 15:03:06.662930: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/michel/anaconda3/envs/UP2024/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "I0000 00:00:1730926989.592129  443332 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 378 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:17:00.0, compute capability: 7.5\n",
      "I0000 00:00:1730926989.594057  443332 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 8680 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1730926989.916930  443580 gpu_backend_lib.cc:579] Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice. This may result in compilation or runtime failures, if the program we try to run uses routines from libdevice.\n",
      "Searched for CUDA in the following directories:\n",
      "  ./cuda_sdk_lib\n",
      "  ipykernel_launcher.runfiles/cuda_nvcc\n",
      "  ipykern/cuda_nvcc\n",
      "  \n",
      "  /usr/local/cuda\n",
      "  /home/michel/anaconda3/envs/UP2024/lib/python3.12/site-packages/tensorflow/python/platform/../../../nvidia/cuda_nvcc\n",
      "  /home/michel/anaconda3/envs/UP2024/lib/python3.12/site-packages/tensorflow/python/platform/../../../../nvidia/cuda_nvcc\n",
      "  /home/michel/anaconda3/envs/UP2024/lib/python3.12/site-packages/tensorflow/python/platform/../../cuda\n",
      "  .\n",
      "You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\n",
      "W0000 00:00:1730926989.958125  443580 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "W0000 00:00:1730926989.959936  443587 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "W0000 00:00:1730926989.962278  443582 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "W0000 00:00:1730926989.965730  443579 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "W0000 00:00:1730926989.968680  443585 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "W0000 00:00:1730926989.971303  443586 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "W0000 00:00:1730926989.973593  443584 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "W0000 00:00:1730926989.975601  443588 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "W0000 00:00:1730926989.978017  443583 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "W0000 00:00:1730926989.984701  443577 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "W0000 00:00:1730926989.987444  443581 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "W0000 00:00:1730926989.991582  443578 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "W0000 00:00:1730926990.001798  443580 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-11-06 15:03:10.599553: W tensorflow/compiler/mlir/tools/kernel_gen/tf_gpu_runtime_wrappers.cc:40] 'cuModuleLoadData(&module, data)' failed with 'CUDA_ERROR_UNSUPPORTED_PTX_VERSION'\n",
      "\n",
      "2024-11-06 15:03:10.599599: W tensorflow/compiler/mlir/tools/kernel_gen/tf_gpu_runtime_wrappers.cc:40] 'cuModuleGetFunction(&function, module, kernel_name)' failed with 'CUDA_ERROR_INVALID_HANDLE'\n",
      "\n",
      "2024-11-06 15:03:10.599612: W tensorflow/core/framework/op_kernel.cc:1829] INTERNAL: 'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, 0, reinterpret_cast<CUstream>(stream), params, nullptr)' failed with 'CUDA_ERROR_INVALID_HANDLE'\n",
      "2024-11-06 15:03:10.599634: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: INTERNAL: 'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, 0, reinterpret_cast<CUstream>(stream), params, nullptr)' failed with 'CUDA_ERROR_INVALID_HANDLE'\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "{{function_node __wrapped__FloorMod_device_/job:localhost/replica:0/task:0/device:GPU:0}} 'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, 0, reinterpret_cast<CUstream>(stream), params, nullptr)' failed with 'CUDA_ERROR_INVALID_HANDLE' [Op:FloorMod] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Ejemplo de creación de un modelo\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSequential\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msigmoid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Entrenar el modelo con datos de ejemplo\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/UP2024/lib/python3.12/site-packages/keras/src/models/sequential.py:76\u001b[0m, in \u001b[0;36mSequential.__init__\u001b[0;34m(self, layers, trainable, name)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m layers:\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd(layer, rebuild\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_rebuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/UP2024/lib/python3.12/site-packages/keras/src/models/sequential.py:141\u001b[0m, in \u001b[0;36mSequential._maybe_rebuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m], InputLayer) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    140\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mbatch_shape\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;66;03m# We can build the Sequential model if the first layer has the\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# `input_shape` property. This is most commonly found in Functional\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m# model.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39minput_shape\n",
      "File \u001b[0;32m~/anaconda3/envs/UP2024/lib/python3.12/site-packages/keras/src/layers/layer.py:226\u001b[0m, in \u001b[0;36mLayer.__new__.<locals>.build_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_open_name_scope():\n\u001b[1;32m    225\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_path \u001b[38;5;241m=\u001b[39m current_path()\n\u001b[0;32m--> 226\u001b[0m     \u001b[43moriginal_build_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# Record build config.\u001b[39;00m\n\u001b[1;32m    228\u001b[0m signature \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(original_build_method)\n",
      "File \u001b[0;32m~/anaconda3/envs/UP2024/lib/python3.12/site-packages/keras/src/models/sequential.py:187\u001b[0m, in \u001b[0;36mSequential.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 187\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;66;03m# Can happen if shape inference is not implemented.\u001b[39;00m\n\u001b[1;32m    190\u001b[0m         \u001b[38;5;66;03m# TODO: consider reverting inbound nodes on layers processed.\u001b[39;00m\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/UP2024/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/UP2024/lib/python3.12/site-packages/keras/src/backend/tensorflow/random.py:19\u001b[0m, in \u001b[0;36m_cast_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m seed\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 19\u001b[0m     seed \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloormod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m seed\n",
      "\u001b[0;31mInternalError\u001b[0m: {{function_node __wrapped__FloorMod_device_/job:localhost/replica:0/task:0/device:GPU:0}} 'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, 0, reinterpret_cast<CUstream>(stream), params, nullptr)' failed with 'CUDA_ERROR_INVALID_HANDLE' [Op:FloorMod] name: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Configuración de memoria GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Ahora puedes importar otros módulos de TensorFlow o ejecutar operaciones de TensorFlow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Ejemplo de creación de un modelo\n",
    "model = Sequential([\n",
    "    Dense(10, activation='relu', input_shape=(4,)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo con datos de ejemplo\n",
    "import numpy as np\n",
    "\n",
    "X_train = np.random.rand(100, 4)\n",
    "y_train = np.random.randint(2, size=100)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs configuradas: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1730927038.322048  444173 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 512 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:17:00.0, compute capability: 7.5\n",
      "I0000 00:00:1730927038.324257  444173 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 512 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1730927038.783188  444691 gpu_backend_lib.cc:579] Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice. This may result in compilation or runtime failures, if the program we try to run uses routines from libdevice.\n",
      "Searched for CUDA in the following directories:\n",
      "  ./cuda_sdk_lib\n",
      "  ipykernel_launcher.runfiles/cuda_nvcc\n",
      "  ipykern/cuda_nvcc\n",
      "  \n",
      "  /usr/local/cuda\n",
      "  /home/michel/anaconda3/envs/UP2024/lib/python3.12/site-packages/tensorflow/python/platform/../../../nvidia/cuda_nvcc\n",
      "  /home/michel/anaconda3/envs/UP2024/lib/python3.12/site-packages/tensorflow/python/platform/../../../../nvidia/cuda_nvcc\n",
      "  /home/michel/anaconda3/envs/UP2024/lib/python3.12/site-packages/tensorflow/python/platform/../../cuda\n",
      "  .\n",
      "You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\n",
      "W0000 00:00:1730927038.809700  444692 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "W0000 00:00:1730927038.814779  444700 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "W0000 00:00:1730927038.819415  444696 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "W0000 00:00:1730927038.823473  444702 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "W0000 00:00:1730927038.827342  444701 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "W0000 00:00:1730927038.832285  444698 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "W0000 00:00:1730927038.841852  444691 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "W0000 00:00:1730927038.846565  444699 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "W0000 00:00:1730927038.851256  444697 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "W0000 00:00:1730927038.855894  444695 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "W0000 00:00:1730927038.860647  444693 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "W0000 00:00:1730927038.866023  444694 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "W0000 00:00:1730927038.870132  444692 gpu_kernel_to_blob_pass.cc:190] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creando modelo: {{function_node __wrapped__FloorMod_device_/job:localhost/replica:0/task:0/device:GPU:0}} 'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, 0, reinterpret_cast<CUstream>(stream), params, nullptr)' failed with 'CUDA_ERROR_INVALID_HANDLE' [Op:FloorMod] name: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 15:03:59.580467: W tensorflow/compiler/mlir/tools/kernel_gen/tf_gpu_runtime_wrappers.cc:40] 'cuModuleLoadData(&module, data)' failed with 'CUDA_ERROR_UNSUPPORTED_PTX_VERSION'\n",
      "\n",
      "2024-11-06 15:03:59.580513: W tensorflow/compiler/mlir/tools/kernel_gen/tf_gpu_runtime_wrappers.cc:40] 'cuModuleGetFunction(&function, module, kernel_name)' failed with 'CUDA_ERROR_INVALID_HANDLE'\n",
      "\n",
      "2024-11-06 15:03:59.580530: W tensorflow/core/framework/op_kernel.cc:1829] INTERNAL: 'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, 0, reinterpret_cast<CUstream>(stream), params, nullptr)' failed with 'CUDA_ERROR_INVALID_HANDLE'\n",
      "2024-11-06 15:03:59.580553: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: INTERNAL: 'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, 0, reinterpret_cast<CUstream>(stream), params, nullptr)' failed with 'CUDA_ERROR_INVALID_HANDLE'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "def configurar_entorno():\n",
    "    \"\"\"\n",
    "    Configura el entorno completo para TensorFlow\n",
    "    \"\"\"\n",
    "    # 1. Configurar CUDA\n",
    "    os.environ['CUDA_DIR'] = '/usr/local/cuda'\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Reducir mensajes\n",
    "\n",
    "    # 2. Configurar GPUs\n",
    "    try:\n",
    "        gpus = tf.config.list_physical_devices('GPU')\n",
    "        if gpus:\n",
    "            for gpu in gpus:\n",
    "                # Configurar memoria limitada\n",
    "                tf.config.set_logical_device_configuration(\n",
    "                    gpu,\n",
    "                    [tf.config.LogicalDeviceConfiguration(memory_limit=512)]\n",
    "                )\n",
    "                \n",
    "            print(f\"GPUs configuradas: {len(gpus)}\")\n",
    "        else:\n",
    "            print(\"No se encontraron GPUs\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error en configuración GPU: {e}\")\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "def crear_modelo():\n",
    "    \"\"\"\n",
    "    Crea un modelo Sequential con la forma correcta\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Input(shape=(10,)),  # Especificar forma de entrada\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Uso\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Configurar entorno\n",
    "    configurar_entorno()\n",
    "    \n",
    "    # 2. Crear modelo\n",
    "    try:\n",
    "        model = crear_modelo()\n",
    "        print(\"\\nResumen del modelo:\")\n",
    "        model.summary()\n",
    "    except Exception as e:\n",
    "        print(f\"Error creando modelo: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limitar_uso_gpu():\n",
    "    \"\"\"\n",
    "    Configura límites más estrictos de GPU\n",
    "    \"\"\"\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            # Usar solo la primera GPU\n",
    "            tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "            \n",
    "            # Limitar memoria a 256MB\n",
    "            tf.config.set_logical_device_configuration(\n",
    "                gpus[0],\n",
    "                [tf.config.LogicalDeviceConfiguration(memory_limit=256)]\n",
    "            )\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "\n",
    "# O simplemente usar CPU\n",
    "def usar_cpu():\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov  6 15:04:30 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.78                 Driver Version: 550.78         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti     Off |   00000000:17:00.0 Off |                  N/A |\n",
      "| 30%   39C    P8             34W /  260W |   10913MiB /  11264MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 2080 Ti     Off |   00000000:65:00.0  On |                  N/A |\n",
      "| 43%   54C    P5             46W /  260W |    1261MiB /  11264MiB |     25%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      3192      G   /usr/lib/xorg/Xorg                              4MiB |\n",
      "|    0   N/A  N/A     17702      C   ...el/anaconda3/envs/UP2024/bin/python      10032MiB |\n",
      "|    0   N/A  N/A    437331      C   ...el/anaconda3/envs/UP2024/bin/python        206MiB |\n",
      "|    0   N/A  N/A    444173      C   ...el/anaconda3/envs/UP2024/bin/python        666MiB |\n",
      "|    1   N/A  N/A      3192      G   /usr/lib/xorg/Xorg                            333MiB |\n",
      "|    1   N/A  N/A      3537      G   /usr/bin/gnome-shell                           35MiB |\n",
      "|    1   N/A  N/A      4215      G   /usr/libexec/xdg-desktop-portal-gnome          65MiB |\n",
      "|    1   N/A  N/A      4408      G   ...seed-version=20241105-050129.381000        175MiB |\n",
      "|    1   N/A  N/A     17702      C   ...el/anaconda3/envs/UP2024/bin/python        154MiB |\n",
      "|    1   N/A  N/A     71511      G   ...erProcess --variations-seed-version        168MiB |\n",
      "|    1   N/A  N/A     73299      G   /usr/bin/nautilus                              12MiB |\n",
      "|    1   N/A  N/A    437331      C   ...el/anaconda3/envs/UP2024/bin/python        154MiB |\n",
      "|    1   N/A  N/A    444173      C   ...el/anaconda3/envs/UP2024/bin/python        154MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvcc\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar repositorio NVIDIA\n",
    "wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin\n",
    "sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600\n",
    "sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/3bf863cc.pub\n",
    "sudo add-apt-repository \"deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/ /\"\n",
    "\n",
    "# Actualizar e instalar\n",
    "sudo apt update\n",
    "sudo apt install cuda"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UP2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
